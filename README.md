<p align="left">
  <img src="doc/title.png" width="800" title="title" alt="title">
</p>

Compositional Generalization in Natual Language Processing. A Paper List. 

TODO: a fancy cover photo

Yao Fu, University of Edinburgh, yao.fu@ed.ac.uk


----

Although seemingly trivial and being easily used everyday, our observation and knowledge of human language is restricted, biased and ultimately finite. 
Yet the variant of human language is at least exponentially large, and potentially infinite. 
How can we generalize to such large space with such limited observation? 
This is the core problem studied by compositional generalization. 

## Table of Content 

## Foundamentals

* Statistical Learning Theory. Percy Liang. CS229T Notes.

## NLP Side

### Semantic Parsing 

* Generalization without systematicity: On the compositional skills of sequence-to-sequence recurrent networks. Brenden M. Lake, Marco Baroni. ICML 2018

* A reproduction study of SCAN. Yao Fu. \[[code](https://github.com/FranxYao/SCAN_reproduce)\]

* Improving Text-to-SQL Evaluation Methodology. Catherine Finegan-Dollak, Jonathan K. Kummerfeld, Li Zhang, Karthik Ramanathan, Sesh Sadasivam, Rui Zhang, Dragomir Radev. 

### Question Answering

### Reading Comprehension 

## ML Side 

### Neural-Symbolic Machines 

### Neural Network Learnability
* Memory-Augmented Recurrent Neural Networks Can Learn Generalized Dyck Languages. Mirac Suzgun, Sebastian Gehrmann, Yonatan Belinkov, Stuart M. Shieber.

* RNNs can generate bounded hierarchical languages with optimal memory. John Hewitt, Michael Hahn, Surya Ganguli, Percy Liang, Christopher D. Manning. EMNLP 2020

* A Formal Hierarchy of RNN Architectures. William Merrill, Gail Weiss, Yoav Goldberg, Roy Schwartz, Noah A. Smith, Eran Yahav. ACL 2020 

* Theoretical Limitations of Self-Attention in Neural Sequence Models. Michael Hahn. TACL 2019

* On the Ability and Limitations of Transformers to Recognize Formal Languages. Satwik Bhattamishra, Kabir Ahuja, Navin Goyal. EMNLP 2020

### Domain Adaptation 

* Understanding Self-Training for Gradual Domain Adaptation. Ananya Kumar, Tengyu Ma, Percy Liang. 

### Invariance 

### Causality
* A Meta-Transfer Objective for Learning to Disentangle Causal Mechanisms. Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Rosemary Ke, SÃ©bastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, Christopher Pal

